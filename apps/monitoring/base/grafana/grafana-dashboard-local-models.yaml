apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: local-models
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  instanceSelector:
    matchLabels:
      dashboards: "grafana"
  folderRef: gitops
  json: >
    {
      "uid": "local-models",
      "title": "Local Models (KServe vLLM)",
      "schemaVersion": 39,
      "version": 1,
      "refresh": "30s",
      "timezone": "browser",
      "panels": [
        {
          "type": "timeseries",
          "title": "CPU Usage (predictor pods)",
          "datasource": { "type": "prometheus", "uid": "prometheus" },
          "gridPos": { "x": 0, "y": 6, "w": 24, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "sum by (pod) (rate(container_cpu_usage_seconds_total{namespace=\"vllm\", pod=~\".*predictor.*\", container!=\"\", image!=\"\"}[5m]))"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "GPU Utilization (%)",
          "datasource": { "type": "prometheus", "uid": "prometheus" },
          "gridPos": { "x": 0, "y": 15, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "avg by (instance, gpu) (DCGM_FI_DEV_GPU_UTIL)"
            }
          ]
        },
        {
          "type": "gauge",
          "title": "GPU Memory Utilization (%)",
          "datasource": { "type": "prometheus", "uid": "prometheus" },
          "gridPos": { "x": 12, "y": 15, "w": 12, "h": 9 },
          "fieldConfig": {
            "defaults": {
              "min": 0,
              "max": 100,
              "unit": "percent",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  { "color": "green", "value": null },
                  { "color": "yellow", "value": 60 },
                  { "color": "red", "value": 85 }
                ]
              }
            }
          },
          "targets": [
            {
              "refId": "A",
              "expr": "100 * (max by (Hostname, gpu) (DCGM_FI_DEV_FB_USED) / on (Hostname, gpu) (max by (Hostname, gpu) (DCGM_FI_DEV_FB_USED) + max by (Hostname, gpu) (DCGM_FI_DEV_FB_FREE)))",
              "instant": true
            }
          ]
        },
        {
          "type": "gauge",
          "title": "GPU Utilization by node (%)",
          "datasource": { "type": "prometheus", "uid": "prometheus" },
          "gridPos": { "x": 0, "y": 24, "w": 12, "h": 9 },
          "fieldConfig": {
            "defaults": {
              "min": 0,
              "max": 100,
              "unit": "percent",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  { "color": "green", "value": null },
                  { "color": "yellow", "value": 60 },
                  { "color": "red", "value": 85 }
                ]
              }
            }
          },
          "targets": [
            {
              "refId": "A",
              "expr": "avg by (node) (label_replace(DCGM_FI_DEV_GPU_UTIL, \"node\", \"$1\", \"Hostname\", \"(.*)\")) and on (node) (sum by (node) (kube_node_status_capacity{resource=\"nvidia_com_gpu\"}) > 0)",
              "instant": true
            }
          ]
        },
        {
          "type": "stat",
          "title": "Predictor pods by GPU node",
          "datasource": { "type": "prometheus", "uid": "prometheus" },
          "gridPos": { "x": 12, "y": 24, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "((count by (node) (max by (pod, node) (kube_pod_info{namespace=\"vllm\", pod=~\".*predictor.*\"}))) and on (node) ((sum by (node) (kube_node_status_capacity{resource=\"nvidia_com_gpu\"}) > 0) unless on (node) (max by (node) (kube_node_role{role=~\"master|control-plane\"})))) or (0 * ((sum by (node) (kube_node_status_capacity{resource=\"nvidia_com_gpu\"}) > 0) unless on (node) (max by (node) (kube_node_role{role=~\"master|control-plane\"}))))",
              "instant": true
            }
          ]
        }
      ]
    }