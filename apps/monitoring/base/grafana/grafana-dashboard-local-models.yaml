apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: local-models
spec:
  instanceSelector:
    matchLabels:
      dashboards: "grafana"
  folderRef: gitops
  json: >
    {
      "uid": "local-models",
      "title": "Local Models (KServe vLLM)",
      "schemaVersion": 39,
      "version": 1,
      "refresh": "30s",
      "timezone": "browser",
      "panels": [
        {
          "type": "stat",
          "title": "Targets Up (vLLM predictors)",
          "gridPos": { "x": 0, "y": 0, "w": 12, "h": 6 },
          "targets": [
            {
              "refId": "A",
              "expr": "sum(up{namespace=\"vllm\"})",
              "instant": true
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "CPU Usage (predictor pods)",
          "gridPos": { "x": 0, "y": 6, "w": 24, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "sum by (pod) (rate(container_cpu_usage_seconds_total{namespace=\"vllm\", pod=~\".*predictor.*\", container!=\"\", image!=\"\"}[5m]))"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "GPU Utilization (%)",
          "gridPos": { "x": 0, "y": 15, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "avg by (instance, gpu) (DCGM_FI_DEV_GPU_UTIL)"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "GPU Memory Used (MiB)",
          "gridPos": { "x": 12, "y": 15, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "avg by (instance, gpu) (DCGM_FI_DEV_FB_USED)"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "GPU Utilization by node (%)",
          "gridPos": { "x": 0, "y": 24, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "avg by (node) (DCGM_FI_DEV_GPU_UTIL)"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "Predictor pods by node",
          "gridPos": { "x": 12, "y": 24, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "count by (node) (kube_pod_info{namespace=\"vllm\", pod=~\".*predictor.*\"})"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "Requests/sec (predictor pods)",
          "gridPos": { "x": 0, "y": 33, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "sum by (pod) (rate(http_requests_total{namespace=\"vllm\", pod=~\".*predictor.*\"}[5m]))"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "p95 latency (s) (predictor pods)",
          "gridPos": { "x": 12, "y": 33, "w": 12, "h": 9 },
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.95, sum by (le, pod) (rate(http_request_duration_seconds_bucket{namespace=\"vllm\", pod=~\".*predictor.*\"}[5m])))"
            }
          ]
        }
      ]
    }
